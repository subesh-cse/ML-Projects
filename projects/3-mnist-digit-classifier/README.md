# MNIST Digit Classification ğŸ§ ğŸ–Šï¸

This project implements a simple Neural Network using TensorFlow and Keras to classify handwritten digits from the MNIST dataset. It includes data visualization, model training, evaluation, and performance metrics.

---


---

## ğŸ“Œ Objective

To build a multi-class classification model that can accurately recognize handwritten digits (0â€“9) from grayscale images using a neural network.

---

## ğŸ“Š Dataset

- **Dataset Name:** MNIST  
- **Description:** 70,000 28Ã—28 pixel grayscale images of handwritten digits (0â€“9)  
- **Source:** Built-in with `keras.datasets`

---

## ğŸ§  Model Architecture

- Input Layer: `28 x 28` image input (flattened)
- Dense Layer 1: 128 neurons with ReLU activation
- Output Layer: 10 neurons with Softmax activation

```python
model = Sequential()
model.add(Input(shape=(28, 28)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))
```

---

## ğŸ“ˆ Results & Visualizations

- **Sample Predictions**: Shows actual images with predicted labels  
- **Accuracy**: Evaluated using test dataset  
- **Confusion Matrix**: Displays class-wise prediction performance  
- **Loss & Accuracy Graphs**: Training vs validation performance

---

## âœ… Performance

| Metric        | Value                         |
|---------------|-------------------------------|
| Test Accuracy | ~97% (varies slightly per run)|
| Loss          | Low and stable                |

---

## ğŸ“¦ Libraries Used

- `TensorFlow` / `Keras`  
- `Matplotlib`  
- `Seaborn`  
- `Scikit-learn`  
- `NumPy`

---

## ğŸš€ How to Run

1. Open the `MNIST_digit_classification.ipynb` notebook in **Google Colab** or **Jupyter Notebook**
2. Run all cells to:
   - Load and preprocess data
   - Train the model
   - Visualize predictions and accuracy

---

## ğŸ“š Learning Outcome

- Understand how neural networks work on image data  
- Learn basic TensorFlow/Keras workflows  
- Gain experience in visualizing predictions and performance

---

## ğŸ’¡ Future Improvements

- Use **CNN (Convolutional Neural Network)** for higher accuracy  
- Add **Dropout** or **Batch Normalization** for better generalization  
- Try **Hyperparameter tuning** for optimization

---


